{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controlled-registration",
   "metadata": {},
   "source": [
    "# ExPloration 03.\n",
    "\n",
    "### 카메라 스티커앱 만들기 첫걸음\n",
    "date: 2021.09.30\n",
    "\n",
    "---\n",
    "\n",
    "### 준비 하기\n",
    "`랜드마크(landmark)`. `조정(alignment)`: 눈, 코, 입 등의 얼굴 각 위치를 찾아내는 기술<br>\n",
    "`keypoint detection`: 랜드마크, 조정보다 큰 개념<br>\n",
    "<br>\n",
    "`opencv`: 이미지 채널로 BGR(파랑, 녹색, 빨강)을 사용\n",
    "(matplotlib, dlib는 RGB)\n",
    "\n",
    "`cv2.imread`('img.png', flag)의 `flag`\n",
    "- 1(cv2.IMREAD_COLOR) \n",
    "    - 이미지 파일을 Color로 읽어들인다.\n",
    "    - 투명한 부분은 무시.\n",
    "    - Default값\n",
    "    \n",
    "- 0(cv2.IMREAD_GRAYSCALE)\n",
    "    - 이미지를 Grayscale로 읽어 들인다.\n",
    "    - 이미지 처리시 중간단계로 많이 사용\n",
    "    \n",
    "- -1(cv2.IMREAD_UNCHANGED)\n",
    "    - alpha channel까지 포함하여 읽어 들인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-hundred",
   "metadata": {},
   "source": [
    "---\n",
    "### face detection\n",
    "> HOG feature를 사용해서 SVM의 sliding window로 얼굴을 찾는다.\n",
    "\n",
    "`HOG`: Histogram of Oriented Gradient\n",
    "\n",
    "`SVM`: Support Vector Machine\n",
    "\n",
    "####  이미지에서 그래디언트(gradient)를 특징으로 사용하는 이유\n",
    "- 픽셀의 RGB값 자체보다는 인접한 픽셀들 사이의 색상 변화율 자체에 오브젝트의 특징이 더욱 정확히 반영될 때가 많기 때문\n",
    "\n",
    "- 단일 픽셀 그래디언트만 다루게 되면 너무 자세하기 때문에 크게 보지 못하게 될 수 있다. 그렇기 때문에 16x16 정사각형을 이용하여 높은 수준에서의 밝음, 어둠의 기본 흐름을 보는 것이 좋다.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "`cvtColor()`: openCV bgr 이미지를 rgb로 변환\n",
    "\n",
    "`이미지 피라미드`: 이미지를 upsampling 방법을 통해 크기를 키우는 것\n",
    "\n",
    "`dlib detector` 는 `dlib.rectangles` 타입의 객체를 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-radiation",
   "metadata": {},
   "source": [
    "---\n",
    "### face landmark\n",
    "\n",
    "`face landmark localization`: 이목구비의 위치를 추론하는 것으로 detection 의 결과물인 bounding box 로 잘라낸(crop) 얼굴 이미지를 이용한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Object keypoint estimation\n",
    "- 객체 내부의 점을 찾는 기술\n",
    "- bounding box를 찾고 box 내부의 keypoint를 예측하는 `top-down`과 이미지 전체의 keypoint를 먼저 찾고 point 관계를 이용해 군집화 해서 box 생성하는 `bottom-up` 알고리즘이 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "`landmark_predictor`: RGB 이미지와 dlib.rectangle을 입력 받아 `dlib.full_object_detection`를 반환\n",
    "\n",
    "`list_points` 는 `tuple (x, y)` 68개로 이루어진 리스트가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_landmarks = []\n",
    "for dlib_rect in dlib_rects:\n",
    "    points = landmark_predictor(img_rgb, dlib_rect)\n",
    "    list_points = list(map(lambda p: (p.x, p.y), points.parts()))\n",
    "    list_landmarks.append(list_points)\n",
    "\n",
    "print(len(list_landmarks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-viewer",
   "metadata": {},
   "source": [
    "### 스티커 적용하기 \n",
    "\n",
    "- 스티커 위치와 크기 조정하기\n",
    "\n",
    "- 스티커 불러오기\n",
    "\n",
    "- 얼굴 위치나 카메라의 거리에 따라 픽셀이 다르기 때문에 비율로 계산할 것!\n",
    "\n",
    "- `opencv` 데이터는 `numpy ndarray` 형태의 데이터를 사용합니다. \n",
    "\n",
    "- `ndarray`는 **음수 인덱스에 접근할 수 없기 때문에 음수에 대한 예외 처리**를 해줘야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-grenada",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 참고 자료\n",
    "\n",
    "[딥러닝(Deep Learning)을 사용한 최신 얼굴 인식(Face Recognition)](https://medium.com/@jongdae.lim/%EA%B8%B0%EA%B3%84-%ED%95%99%EC%8A%B5-machine-learning-%EC%9D%80-%EC%A6%90%EA%B2%81%EB%8B%A4-part-4-63ed781eee3c)\n",
    "\n",
    "[Image Pyramids - gramman 0.1 documentation](https://opencv-python.readthedocs.io/en/latest/doc/14.imagePyramid/imagePyramid.html)\n",
    "\n",
    "[Classes - dlib documentation](http://dlib.net/python/index.html#dlib.rectangles)\n",
    "\n",
    "[AFLW dataset](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/)\n",
    "\n",
    "[One Millisecond Face Alignment with an Ensemble of Regression Trees](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
